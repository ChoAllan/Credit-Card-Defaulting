{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "136e0753-e292-4db5-a77f-7c435681432b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "%matplotlib inline\n",
    "import sys\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import xgboost as xgb\n",
    "from sklearn.compose import ColumnTransformer, make_column_transformer\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import (\n",
    "    classification_report,\n",
    "    confusion_matrix,\n",
    "    f1_score,\n",
    "    make_scorer,\n",
    "    plot_confusion_matrix,\n",
    ")\n",
    "from sklearn.model_selection import (\n",
    "    GridSearchCV,\n",
    "    RandomizedSearchCV,\n",
    "    cross_val_score,\n",
    "    cross_validate,\n",
    "    train_test_split,\n",
    ")\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder, OrdinalEncoder, StandardScaler\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bff3d7ab-7b65-458f-9c6b-da01a46eb637",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Credit Card Payment Default\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f03930e3-bf71-4f53-a2aa-a8ad64f258d5",
   "metadata": {
    "tags": []
   },
   "source": [
    "## The Problem\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c3301a7-0041-4478-9900-6b9b7e5cf49a",
   "metadata": {},
   "source": [
    "**In class we worked with a Default of Credit Card Clients Dataset to estimate whether a person will default their credit card bills. With the same goal in mind, I will be looking to improve the f1 score of models I have previously created using different techniques. Models with higher f1 scores will be better at detecting false megative cases. In this dataset, false negative cases occur when the model classifies that someone will not default payment when they will. We want to detect false negative cases as it is more detrimental to the credit card company since there is potential to lose money.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9e9a2d8-7283-4e0f-8de6-9b174e837a5d",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8536f29f-1b7b-4589-9969-fcc487ef8f9b",
   "metadata": {},
   "source": [
    "## Data Preprocessing\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "716d91f9-bb35-4ed2-b4f4-35d1416a796c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading dataset from CSV file\n",
    "cc_df = pd.read_csv(\"data/UCI_Credit_Card.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7360827-19e6-4e68-b494-2531060879db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# splitting of data into train and test portions\n",
    "\n",
    "X = cc_df.drop(columns = [\"default.payment.next.month\", \"ID\"])\n",
    "y = cc_df[\"default.payment.next.month\"]\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.1, random_state=123\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bc1e18c-5e70-4bc8-8e90-8b27c6e4dda2",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ced05bd9-84cb-4eca-a6d7-af5ba4301992",
   "metadata": {},
   "outputs": [],
   "source": [
    "cc_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "196d3822-64fd-42d8-a515-de40d1d098ae",
   "metadata": {},
   "source": [
    "**As I look through the features of the data set, ID feature could be unhelpful in predicting the outcome. Data seems complete as there are no unknown values so no imputation will be needed. It would be interesting to see how big of a factor marriage, age and sex is in determining whether someone will default their payment.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "421d7544-4f62-4db4-a85d-9f14d4e2154f",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb3256c4-0695-41eb-8e46-e52d3b81f5e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "pay = cc_df[cc_df['default.payment.next.month'] == 1]\n",
    "\n",
    "nopay = cc_df[cc_df['default.payment.next.month'] == 0]\n",
    "\n",
    "print(\"pay: \" + str(pay.shape))\n",
    "print(\"nopay: \" + str(nopay.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f99ba885-82bc-4436-9b1b-522daa0a19fc",
   "metadata": {},
   "source": [
    "**From the information given above, we can see that there is a class imbalance of the target class of 23364 who did not default and 6636 of who defaulted.**\n",
    "<br><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a24d436b-eaf4-4ac4-b731-67670922e53a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "features = []\n",
    "\n",
    "for col in cc_df.columns:\n",
    "    features.append(col)\n",
    "\n",
    "figures = dict()\n",
    "\n",
    "for feature in features:\n",
    "    plt.hist(nopay[feature], alpha=1, bins=50, label=\"0\")\n",
    "    plt.hist(pay[feature], alpha=0.5, bins=50, label=\"1\")\n",
    "    plt.legend(loc=\"best\")\n",
    "\n",
    "    plt.xlabel(feature)\n",
    "    plt.ylabel(\"count\")\n",
    "    plt.title(f\"Histogram of {feature} by target class\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b16cc1a-1fe1-4454-8d1b-807fb49b48f9",
   "metadata": {},
   "source": [
    "**LIMIT_BAL and AGE seems like a relevant feature for the given prediction task.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93942daf-3d7a-4442-a5fc-d5525d49a44c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cc_df.plot(\n",
    "    kind='scatter',\n",
    "    x='AGE',\n",
    "    y='PAY_AMT1',\n",
    "    c='LIMIT_BAL',\n",
    "    cmap=plt.get_cmap(\"jet\"),\n",
    "    figsize=(10,10),\n",
    "    colorbar=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f64b54bf-3813-44af-a1d0-44c5c35918b6",
   "metadata": {},
   "source": [
    "**This might suggest that middle-age people (30-50) have higher LIMIT_BAL which in turn will have higher payments.**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1440b1f-3a53-496a-9e12-511d30470982",
   "metadata": {},
   "source": [
    "## METRICS\n",
    "\n",
    "**It is more detrimental to the credit card company to not be able to detect when people are going to default; that is when we are interested in false negatives. Due to class imbalances, we will be using F1, precision and recall scores instead of accuracy. Not being able to detect people who will default increases the opportunity cost of the company, thus we should be trying to optimize recall scores instead of precision scores.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c2d9389-979f-40a3-848d-51ea5a9d77d8",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bbf9706-d337-4b42-9296-905aaeb4f9c7",
   "metadata": {},
   "source": [
    "## Preprocessing and Transformations\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbed60b9-a269-43e4-bf0a-670d9e76aa5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_feats = [\n",
    "    'PAY_0',\n",
    "    'PAY_2',\n",
    "    'PAY_3',\n",
    "    'PAY_4',\n",
    "    'PAY_5',\n",
    "    'PAY_6',\n",
    "    'MARRIAGE',\n",
    "    'EDUCATION'\n",
    "]\n",
    "\n",
    "numeric_feats = [\n",
    "    'LIMIT_BAL',\n",
    "    'AGE',\n",
    "    'BILL_AMT1',\n",
    "    'BILL_AMT2',\n",
    "    'BILL_AMT3',\n",
    "    'BILL_AMT4',\n",
    "    'BILL_AMT5',\n",
    "    'BILL_AMT6',\n",
    "    'PAY_AMT1',\n",
    "    'PAY_AMT2',\n",
    "    'PAY_AMT3',\n",
    "    'PAY_AMT4',\n",
    "    'PAY_AMT5',\n",
    "    'PAY_AMT6',\n",
    "]\n",
    "    \n",
    "binary_feats = [\n",
    "    'SEX'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "769f8f9d-2779-44ec-895d-a8cc30f32150",
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_transformer = make_pipeline(StandardScaler())\n",
    "\n",
    "\n",
    "categorical_transformer = make_pipeline(\n",
    "    OneHotEncoder(handle_unknown=\"ignore\", sparse=False),\n",
    ")\n",
    "\n",
    "binary_transformer = make_pipeline(\n",
    "    OneHotEncoder(drop=\"if_binary\", dtype=int),\n",
    ")\n",
    "\n",
    "\n",
    "preprocessor = make_column_transformer(\n",
    "    (StandardScaler(), numeric_feats), \n",
    "    (OneHotEncoder(drop=\"if_binary\", dtype=int), binary_feats),    \n",
    "    (OneHotEncoder(handle_unknown=\"ignore\", sparse=False), categorical_feats),\n",
    ")\n",
    "\n",
    "transformed = preprocessor.fit_transform(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "affa6715-635f-4d3c-b46e-8359bf13ea4e",
   "metadata": {},
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0d0ae5e-659a-486c-bfc1-c95994d34330",
   "metadata": {},
   "source": [
    "## Baseline Model\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5048be3c-c0bd-4761-bd9d-37db91145a64",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_std_cross_val_scores(model, X_train, y_train, **kwargs):\n",
    "    \"\"\"\n",
    "    Returns mean and std of cross validation\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    model :\n",
    "        scikit-learn model\n",
    "    X_train : numpy array or pandas DataFrame\n",
    "        X in the training data\n",
    "    y_train :\n",
    "        y in the training data\n",
    "\n",
    "    Returns\n",
    "    ----------\n",
    "        pandas Series with mean scores from cross_validation\n",
    "    \"\"\"\n",
    "\n",
    "    scores = cross_validate(model, X_train, y_train, **kwargs)\n",
    "\n",
    "    mean_scores = pd.DataFrame(scores).mean()\n",
    "    std_scores = pd.DataFrame(scores).std()\n",
    "    out_col = []\n",
    "\n",
    "    for i in range(len(mean_scores)):\n",
    "        out_col.append((f\"%0.3f (+/- %0.3f)\" % (mean_scores[i], std_scores[i])))\n",
    "\n",
    "    return pd.Series(data=out_col, index=mean_scores.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e32cfdf-8877-4175-9a2d-37d8a087057c",
   "metadata": {},
   "outputs": [],
   "source": [
    "scoring = [\n",
    "    \"f1\",\n",
    "    \"recall\",\n",
    "    \"accuracy\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67aee9d2-6f17-4b77-9e72-2b583dd9be13",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_dict = {}\n",
    "\n",
    "dummy = DummyClassifier(strategy=\"prior\")\n",
    "pipe = make_pipeline(preprocessor, dummy)\n",
    "results_dict[\"dummy\"] = mean_std_cross_val_scores(\n",
    "    pipe, X_train, y_train, cv=5, return_train_score=True, scoring = scoring\n",
    ")\n",
    "pd.DataFrame(results_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73e78600-7ef1-4e83-b0cd-065a2cdadd0d",
   "metadata": {},
   "source": [
    " \n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61cd1cae-098f-4b0c-adb1-2cd80a8afd93",
   "metadata": {},
   "source": [
    "## Linear Models\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77aa5537-695f-49f1-b96c-954292ba00dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# first attempt \n",
    "\n",
    "lr = LogisticRegression(max_iter=1000, class_weight='balanced')\n",
    "scores = cross_validate(lr, X_train, y_train, return_train_score=True, scoring=scoring)\n",
    "pd.DataFrame(scores).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "611067fe-b20c-4390-9152-9865e4c4bd15",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = make_pipeline(preprocessor, LogisticRegression(max_iter=1000, class_weight='balanced'))\n",
    "\n",
    "param_grid = {\n",
    "    \"logisticregression__C\": 2.0 ** np.arange(-4, 4)\n",
    "}\n",
    "\n",
    "search = GridSearchCV(\n",
    "    pipe,\n",
    "    param_grid,\n",
    "    verbose=1,\n",
    "    n_jobs=-1,\n",
    "    return_train_score=True,\n",
    "    scoring=\"f1\",\n",
    ")\n",
    "search.fit(X_train, y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42016be6-d506-4dc9-89e3-82038c9edd71",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_results_df = pd.DataFrame(search.cv_results_)[\n",
    "    [\n",
    "        \"mean_test_score\",\n",
    "        \"mean_train_score\",\n",
    "        \"param_logisticregression__C\",\n",
    "        \"rank_test_score\",\n",
    "    ]\n",
    "]\n",
    "grid_results_df = grid_results_df.sort_values(by=\"mean_test_score\", ascending=False)\n",
    "grid_results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8509b526-aa15-42e0-80d8-8aa50078050d",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_results_df.describe()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01ade3d3-1d25-44ac-acce-b2cfdc55e25f",
   "metadata": {},
   "source": [
    "**We use f1 scores for testing in order to counteract class imbalances. From the results above, we can see that the mean f1 scores is 0.532150 with a std of +/-0.000679. If we compare that to the dummy classifier(f1 = 0) and first attempt(f1 = 0.419531), the optimized logistic regression model is significantly better. Given the chart above, we can see that C = 0.0625 gives the best f1 score of 0.533144.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef5fd4cb-f82f-4119-8885-f827a61b57b3",
   "metadata": {},
   "source": [
    " \n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67ab7516-aefd-44f4-998d-ce32b9c6b9ec",
   "metadata": {},
   "source": [
    "## Different Classifiers\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1e9ff15-0a93-41e5-ba11-6d2aa538cd76",
   "metadata": {},
   "outputs": [],
   "source": [
    "from catboost import CatBoostClassifier\n",
    "from lightgbm.sklearn import LGBMClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "pipe_lr = make_pipeline(\n",
    "    preprocessor, LogisticRegression(max_iter=2000, random_state=123)\n",
    ")\n",
    "pipe_dt = make_pipeline(preprocessor, DecisionTreeClassifier(random_state=123))\n",
    "pipe_rf = make_pipeline(preprocessor, RandomForestClassifier(random_state=123))\n",
    "pipe_xgb = make_pipeline(\n",
    "    preprocessor, XGBClassifier(random_state=123, eval_metric=\"logloss\", verbosity=0)\n",
    ")\n",
    "pipe_lgbm = make_pipeline(preprocessor, LGBMClassifier(random_state=123))\n",
    "pipe_catboost = make_pipeline(\n",
    "    preprocessor, CatBoostClassifier(verbose=0, random_state=123)\n",
    ")\n",
    "classifiers = {\n",
    "    \"logistic regression\": pipe_lr,\n",
    "    \"decision tree\": pipe_dt,\n",
    "    \"random forest\": pipe_rf,\n",
    "    \"XGBoost\": pipe_xgb,\n",
    "    \"LightGBM\": pipe_lgbm,\n",
    "    \"CatBoost\": pipe_catboost,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a34bc20e-8f07-464e-9482-919fa76bce09",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {}\n",
    "import warnings\n",
    "\n",
    "warnings.simplefilter(action=\"ignore\", category=DeprecationWarning)\n",
    "warnings.simplefilter(action=\"ignore\", category=UserWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b00505e-537b-437e-aa10-368e27c90bac",
   "metadata": {},
   "outputs": [],
   "source": [
    "for (name, model) in classifiers.items():\n",
    "    results[name] = mean_std_cross_val_scores(\n",
    "        model, X_train, y_train, return_train_score=True, scoring=scoring\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e5776a2-7c6e-4601-b815-555d592da61b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(results).T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "328998eb-3644-43fe-97ea-6a0e23448ba8",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "524d61ea-c946-478b-9893-25fe02e9d465",
   "metadata": {},
   "source": [
    "## Hyperparameter Optimization\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "743feaf8-7e22-4038-b61b-f39d57f0f8ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "lgbm_pipe = make_pipeline(preprocessor, LGBMClassifier(random_state=123))\n",
    "\n",
    "param_grid = {\n",
    "    \"lgbmclassifier__max_depth\": 10*np.arange(1, 50, 10),\n",
    "    \"lgbmclassifier__num_leaves\": 2**np.arange(1, 50, 10),\n",
    "}\n",
    "\n",
    "lgbm_search = GridSearchCV(\n",
    "    lgbm_pipe,\n",
    "    param_grid,\n",
    "    cv = 5,\n",
    "    n_jobs=-1,\n",
    "    return_train_score=True,\n",
    "    scoring=\"f1\",\n",
    ")\n",
    "lgbm_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20e482e9-048c-4a9c-bbc0-7adea8ac16f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "lgbm_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8df8024-6688-4947-9f24-de7538f5d98c",
   "metadata": {},
   "outputs": [],
   "source": [
    "lgbm_search.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98caf5f8-8c1c-41bc-9b07-e6318f9aca9b",
   "metadata": {},
   "source": [
    "**The unoptimized model(f1 = 0.480 performed better than its optimized model(f1 = 0.47148175331599296); this may be due to randomness or luck. However, LightGBM in general performed worse than logistic regression model(f1 = 0.533144). This suggests that logistic regression may be the best model we have to accurately predict our target value.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02389d94-54e5-448b-8326-2cd848e838b1",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f577c16-bb4b-4f3c-8703-2feaf16b6ae6",
   "metadata": {},
   "source": [
    "## Interpretation of Feature Importances\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7db1fd7-c950-420a-8343-60a9d1935d36",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_pipe = make_pipeline(preprocessor, LogisticRegression(max_iter=1000, class_weight='balanced', C = 0.0625))\n",
    "best_pipe.fit(X_train, y_train)\n",
    "\n",
    "coeffs = best_pipe.named_steps[\"logisticregression\"].coef_.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "842d765a-2abf-4b5c-82d1-346cedc45e98",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor.named_transformers_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09ad7271-40b7-4159-aa9d-d2ce07341182",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_columns = (\n",
    "    numeric_feats\n",
    "    + binary_feats\n",
    "    + list(\n",
    "        preprocessor.named_transformers_[\"onehotencoder-2\"].get_feature_names(\n",
    "            categorical_feats\n",
    "        )\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e112b744-0c0b-46ee-a620-d15f0d66cfb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_columns = (\n",
    "    numeric_feats\n",
    "    + binary_feats\n",
    "    + list(\n",
    "        preprocessor.named_transformers_[\"onehotencoder-2\"].get_feature_names(\n",
    "            categorical_feats\n",
    "        )\n",
    "    )\n",
    ")\n",
    "features = pd.DataFrame(coeffs, index=new_columns, columns=[\"Coefficient\"])\n",
    "features.sort_values(by = \"Coefficient\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32362d84-8d8d-4799-b1e3-c52a0435b03f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mglearn\n",
    "mglearn.tools.visualize_coefficients(coeffs, new_columns, n_top_features=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5fe0dc8-e78e-45a2-9fab-eae2e22d03c6",
   "metadata": {},
   "source": [
    "**The top 3 features with biggest coefficients: Pay_0_2, Pay_0_3, Education_2.**\n",
    "\n",
    "**The bottom 3 features with smallest coefficients: Pay_0_0, Pay_0_2, Education_5.**\n",
    "\n",
    "**These features play the biggest factors in determining whether someone will default their payment or not. Pay_0_0 represents whether someone will pay their entire balance for that month on time. That makes sense since people who will pay their statement on time will not default their payment. Pay_0_2 represents whether someone will delay payment for two months. This suggests that people will most likely default their payment if they have delayed their payment for 2 months. Overall, the top and bottom features make sense on why they have their respective coefficients.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f9e246d-0ff6-4c5f-82aa-8ecf64d03333",
   "metadata": {},
   "outputs": [],
   "source": [
    "search.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "379b9cad-a750-443e-b9a2-b2f439a0b05c",
   "metadata": {},
   "source": [
    "**1. Final test Score: 0.5391891891891891, F1 Score: 0.532150**\n",
    "\n",
    "**2. My initial assumptions was that marriage and age would play a role in whether someone would default payment. However, the model seems to suggest otherwise. The final test score seems really low and I would not deploy this model in real life.**\n",
    "\n",
    "**3. Ways to improve performance/interpretability:**\n",
    "\n",
    "**Research and collect features that should play a role in whether payments would be defaulted\n",
    "Find the best hyper parameters for the all the models used and then compared F1 scores\n",
    "Try removing features that have small coefficients(magnitude wise)**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:cpsc330]",
   "language": "python",
   "name": "conda-env-cpsc330-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
